{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:37.625684Z",
     "iopub.status.busy": "2023-11-22T09:16:37.625061Z",
     "iopub.status.idle": "2023-11-22T09:16:50.980358Z",
     "shell.execute_reply": "2023-11-22T09:16:50.979658Z",
     "shell.execute_reply.started": "2023-11-22T09:16:37.625583Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import pickle\n",
    "import os.path\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go\n",
    "import spacy\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:50.982284Z",
     "iopub.status.busy": "2023-11-22T09:16:50.982011Z",
     "iopub.status.idle": "2023-11-22T09:16:50.986368Z",
     "shell.execute_reply": "2023-11-22T09:16:50.985600Z",
     "shell.execute_reply.started": "2023-11-22T09:16:50.982242Z"
    }
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MBTI (Myers-Briggs Type Indicator) is an introspective self-report questionnaire indicating differing psychological preferences (cognitive functions) in how people perceive the world and make decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This study was made based on the kaggle dataset https://www.kaggle.com/zeyadkhalid/mbti-personality-types-500-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As said, this dataset doesn't has any stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Stop words\" are words that appears so frequently that don't require tagging as thoroughly as nouns, verbs and modifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the library Spacy to see examples of english stop words\n",
    "\n",
    "Spacy is the Industrial Strength Natural Language Processing: https://spacy.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:50.987648Z",
     "iopub.status.busy": "2023-11-22T09:16:50.987401Z",
     "iopub.status.idle": "2023-11-22T09:16:51.813046Z",
     "shell.execute_reply": "2023-11-22T09:16:51.812306Z",
     "shell.execute_reply.started": "2023-11-22T09:16:50.987609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fifteen', 'it', 'two', 'many', 'made', 'our', 'until', 'bottom', 'your', 'except', 'last', 'up', 'side', 'becomes', 'well', 'should', 'she', 'just', 'when', 'much', 'what', 'hence', 'more', 'again', 'her', '‘ll', 'most', 'in', 'always', 'how', 'by', 'either', 'to', 'whom', 'whenever', 'may', 'can', 'over', 'neither', 'namely', 'amongst', 'meanwhile', 'whereas', 'mine', 'whatever', 'very', 'they', 'one', 'anything', 'them', 'n’t', 'him', 'please', 'myself', \"'ve\", 'why', 'behind', 'some', 'alone', 'such', 'as', 'other', 'us', 'ca', 'are', 'already', 'rather', 'being', 'so', 'cannot', \"'s\", 'once', 'i', 'everything', 'yourself', 'for', 'less', 'latter', 'perhaps', 'often', 'noone', '‘m', 'seems', 'somehow', 'eight', 'thereafter', 'moreover', 'something', 'whoever', 'therein', 'herein', 'n‘t', 'been', 'a', 'has', 'unless', 'afterwards', 'quite', 'thereby', 'various', 'whose', 'between', 'nine', 'elsewhere', 'than', 'and', 'twelve', 'ten', '‘d', 'he', 'nobody', 'enough', '’m', 'per', 'herself', '’ve', 'amount', 'beyond', 'make', 'hundred', 'five', 'still', 'twenty', 'almost', 'no', 'his', 'this', 'beforehand', 'off', 'both', 'onto', 'since', 'from', 'hereby', 'anyone', 'might', 'became', 'have', 'would', 'next', 'among', 'also', 'under', 'whole', 'an', \"'d\", 'we', 'hers', 'further', 'whereafter', 'will', 'am', 'not', 'therefore', 'every', 'those', 'during', \"'ll\", 'nowhere', 'does', '’ll', '‘ve', 'although', 'whereby', 'hereafter', 'wherever', 'keep', 'below', 'before', 'ourselves', 'anyway', 'indeed', 'upon', 'using', 'another', 'thus', '‘re', 'get', 'after', 'few', 'around', 'whence', 'towards', 'hereupon', 'sixty', 'could', 'done', 'if', 'now', 'others', 'whether', 'first', 'whereupon', 'regarding', 'nevertheless', 'toward', \"n't\", \"'m\", 'everywhere', 'back', 'there', 'third', '’d', 'serious', 'across', 'take', 'else', 'together', 'into', 'nor', 'but', '‘s', 'on', 'against', 'down', 'seemed', 'least', 'ever', 'becoming', 'doing', 'himself', 'that', 'top', 'about', 'these', 'show', 'move', 'the', 'seem', 'me', 'while', 'where', 'sometimes', 'which', 'sometime', '’re', 'several', 'wherein', 'is', 'themselves', 'only', 'of', 'did', 'seeming', \"'re\", 'you', 'empty', 'four', 'ours', 'otherwise', 'anywhere', 're', 'formerly', 'too', 'though', 'call', '’s', 'latterly', 'my', 'thereupon', 'part', 'any', 'front', 'had', 'however', 'whither', 'with', 'used', 'none', 'eleven', 'who', 'mostly', 'somewhere', 'without', 'nothing', 'must', 'own', 'out', 'were', 'besides', 'someone', 'here', 'really', 'everyone', 'above', 'each', 'forty', 'full', 'thru', 'itself', 'all', 'through', 'or', 'become', 'within', 'never', 'say', 'be', 'throughout', 'anyhow', 'fifty', 'beside', 'see', 'do', 'same', 'six', 'its', 'former', 'due', 'go', 'three', 'name', 'via', 'then', 'their', 'because', 'along', 'was', 'yours', 'even', 'yet', 'yourselves', 'give', 'put', 'at', 'thence'}\n"
     ]
    }
   ],
   "source": [
    "# Load one of the availables trained pipelines for English\n",
    "# English pipeline optimized for CPU. Components: tok2vec, tagger, parser, senter, ner, attribute_ruler, lemmatizer.\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "# stop words built in spacy (english)\n",
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:51.815780Z",
     "iopub.status.busy": "2023-11-22T09:16:51.815199Z",
     "iopub.status.idle": "2023-11-22T09:16:51.820138Z",
     "shell.execute_reply": "2023-11-22T09:16:51.819448Z",
     "shell.execute_reply.started": "2023-11-22T09:16:51.815739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of default stop words : 326\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of default stop words : {len(nlp.Defaults.stop_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:51.821151Z",
     "iopub.status.busy": "2023-11-22T09:16:51.820957Z",
     "iopub.status.idle": "2023-11-22T09:16:51.835487Z",
     "shell.execute_reply": "2023-11-22T09:16:51.834312Z",
     "shell.execute_reply.started": "2023-11-22T09:16:51.821126Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if a word is a stop word\n",
    "nlp.vocab['is'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:51.836663Z",
     "iopub.status.busy": "2023-11-22T09:16:51.836486Z",
     "iopub.status.idle": "2023-11-22T09:16:51.844751Z",
     "shell.execute_reply": "2023-11-22T09:16:51.843968Z",
     "shell.execute_reply.started": "2023-11-22T09:16:51.836640Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['below'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:51.845859Z",
     "iopub.status.busy": "2023-11-22T09:16:51.845679Z",
     "iopub.status.idle": "2023-11-22T09:16:51.855720Z",
     "shell.execute_reply": "2023-11-22T09:16:51.854962Z",
     "shell.execute_reply.started": "2023-11-22T09:16:51.845837Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['btw'].is_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As said before, this dataset also has Lemmatization preprocess feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to understand lemmatization, first we'll look at the concept of Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming is used to return similarities words on the search process. \n",
    " \n",
    " - Example: search=boat, also returns \"boats\" and \"boating\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a sophisticated stemmer, the SnowballStemmer from NLTK (natural language toolkit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:51.856940Z",
     "iopub.status.busy": "2023-11-22T09:16:51.856744Z",
     "iopub.status.idle": "2023-11-22T09:16:51.864405Z",
     "shell.execute_reply": "2023-11-22T09:16:51.863636Z",
     "shell.execute_reply.started": "2023-11-22T09:16:51.856916Z"
    }
   },
   "outputs": [],
   "source": [
    "s_stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:51.865852Z",
     "iopub.status.busy": "2023-11-22T09:16:51.865576Z",
     "iopub.status.idle": "2023-11-22T09:16:51.874711Z",
     "shell.execute_reply": "2023-11-22T09:16:51.873895Z",
     "shell.execute_reply.started": "2023-11-22T09:16:51.865816Z"
    }
   },
   "outputs": [],
   "source": [
    "words = ['run', 'runner', 'ran', 'runs', 'easily', 'fairly', 'fairness','boats','boating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:51.876097Z",
     "iopub.status.busy": "2023-11-22T09:16:51.875688Z",
     "iopub.status.idle": "2023-11-22T09:16:51.888906Z",
     "shell.execute_reply": "2023-11-22T09:16:51.888171Z",
     "shell.execute_reply.started": "2023-11-22T09:16:51.876058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run ------> run\n",
      "runner ------> runner\n",
      "ran ------> ran\n",
      "runs ------> run\n",
      "easily ------> easili\n",
      "fairly ------> fair\n",
      "fairness ------> fair\n",
      "boats ------> boat\n",
      "boating ------> boat\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+ ' ------> ' + s_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look about Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In constrast with stemming, Lemmatization looks beyond word reduction, and considers a language's full vocabulary to apply a morphological analysis to words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:51.892000Z",
     "iopub.status.busy": "2023-11-22T09:16:51.891792Z",
     "iopub.status.idle": "2023-11-22T09:16:51.897893Z",
     "shell.execute_reply": "2023-11-22T09:16:51.897076Z",
     "shell.execute_reply.started": "2023-11-22T09:16:51.891975Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to display lemmas\n",
    "def show_lemmas(text):\n",
    "    for token in text:\n",
    "        print(f'{token.text:{12}} {token.pos_:{6}} {token.lemma:<{22}} {token.lemma_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:51.899121Z",
     "iopub.status.busy": "2023-11-22T09:16:51.898874Z",
     "iopub.status.idle": "2023-11-22T09:16:51.927535Z",
     "shell.execute_reply": "2023-11-22T09:16:51.926798Z",
     "shell.execute_reply.started": "2023-11-22T09:16:51.899095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I            PRON   4690420944186131903    I\n",
      "saw          VERB   11925638236994514241   see\n",
      "eighteen     NUM    9609336664675087640    eighteen\n",
      "mice         NOUN   1384165645700560590    mouse\n",
      "today        NOUN   11042482332948150395   today\n",
      "!            PUNCT  17494803046312582752   !\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"I saw eighteen mice today!\")\n",
    "show_lemmas(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:51.929182Z",
     "iopub.status.busy": "2023-11-22T09:16:51.928921Z",
     "iopub.status.idle": "2023-11-22T09:16:51.942854Z",
     "shell.execute_reply": "2023-11-22T09:16:51.942170Z",
     "shell.execute_reply.started": "2023-11-22T09:16:51.929147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I            PRON   4690420944186131903    I\n",
      "am           AUX    10382539506755952630   be\n",
      "meeting      VERB   6880656908171229526    meet\n",
      "him          PRON   1655312771067108281    he\n",
      "tomorrow     NOUN   3573583789758258062    tomorrow\n",
      "at           ADP    11667289587015813222   at\n",
      "the          DET    7425985699627899538    the\n",
      "meeting      NOUN   14798207169164081740   meeting\n",
      ".            PUNCT  12646065887601541794   .\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"I am meeting him tomorrow at the meeting.\")\n",
    "show_lemmas(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to talk about Text Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preprocess data it's time to extract features from the text in order to prepare the machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:51.944467Z",
     "iopub.status.busy": "2023-11-22T09:16:51.944109Z",
     "iopub.status.idle": "2023-11-22T09:16:51.948483Z",
     "shell.execute_reply": "2023-11-22T09:16:51.947732Z",
     "shell.execute_reply.started": "2023-11-22T09:16:51.944430Z"
    }
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:51.949886Z",
     "iopub.status.busy": "2023-11-22T09:16:51.949617Z",
     "iopub.status.idle": "2023-11-22T09:16:51.957655Z",
     "shell.execute_reply": "2023-11-22T09:16:51.956976Z",
     "shell.execute_reply.started": "2023-11-22T09:16:51.949851Z"
    }
   },
   "outputs": [],
   "source": [
    "phrase = [\"I'd like to have a glass of water please\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:51.959093Z",
     "iopub.status.busy": "2023-11-22T09:16:51.958770Z",
     "iopub.status.idle": "2023-11-22T09:16:51.971885Z",
     "shell.execute_reply": "2023-11-22T09:16:51.971131Z",
     "shell.execute_reply.started": "2023-11-22T09:16:51.959058Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit Vectorizer to the Data (build a vocab, count the number of words...)\n",
    "# Learn a vocabulary dictionary of all tokens in the raw documents\n",
    "count_vect.fit(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:51.973097Z",
     "iopub.status.busy": "2023-11-22T09:16:51.972892Z",
     "iopub.status.idle": "2023-11-22T09:16:51.981522Z",
     "shell.execute_reply": "2023-11-22T09:16:51.980779Z",
     "shell.execute_reply.started": "2023-11-22T09:16:51.973071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['glass', 'have', 'like', 'of', 'please', 'to', 'water']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show features\n",
    "count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:51.982757Z",
     "iopub.status.busy": "2023-11-22T09:16:51.982535Z",
     "iopub.status.idle": "2023-11-22T09:16:51.994003Z",
     "shell.execute_reply": "2023-11-22T09:16:51.993201Z",
     "shell.execute_reply.started": "2023-11-22T09:16:51.982732Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x7 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Learn the vocabulary dictionary and return document-term matrix\n",
    "count_vect.fit_transform(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:51.997141Z",
     "iopub.status.busy": "2023-11-22T09:16:51.996887Z",
     "iopub.status.idle": "2023-11-22T09:16:52.005651Z",
     "shell.execute_reply": "2023-11-22T09:16:52.004902Z",
     "shell.execute_reply.started": "2023-11-22T09:16:51.997114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'like': 2, 'to': 5, 'have': 1, 'glass': 0, 'of': 3, 'water': 6, 'please': 4}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows a mapping of terms to feature indices.\n",
    "count_vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative to CountVectorizer is the TfidVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfidVectorizer calculates an inverse frequency for each word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the dataset into a pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to read the dataset and make a simple exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:52.006851Z",
     "iopub.status.busy": "2023-11-22T09:16:52.006628Z",
     "iopub.status.idle": "2023-11-22T09:16:59.444770Z",
     "shell.execute_reply": "2023-11-22T09:16:59.443900Z",
     "shell.execute_reply.started": "2023-11-22T09:16:52.006824Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/mbti-personality-types-500-dataset/MBTI 500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:59.446084Z",
     "iopub.status.busy": "2023-11-22T09:16:59.445859Z",
     "iopub.status.idle": "2023-11-22T09:16:59.460545Z",
     "shell.execute_reply": "2023-11-22T09:16:59.459546Z",
     "shell.execute_reply.started": "2023-11-22T09:16:59.446055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posts</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>know intj tool use interaction people excuse a...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rap music ehh opp yeah know valid well know fa...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>preferably p hd low except wew lad video p min...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drink like wish could drink red wine give head...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>space program ah bad deal meing freelance max ...</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               posts  type\n",
       "0  know intj tool use interaction people excuse a...  INTJ\n",
       "1  rap music ehh opp yeah know valid well know fa...  INTJ\n",
       "2  preferably p hd low except wew lad video p min...  INTJ\n",
       "3  drink like wish could drink red wine give head...  INTJ\n",
       "4  space program ah bad deal meing freelance max ...  INTJ"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:59.461740Z",
     "iopub.status.busy": "2023-11-22T09:16:59.461530Z",
     "iopub.status.idle": "2023-11-22T09:16:59.470975Z",
     "shell.execute_reply": "2023-11-22T09:16:59.470203Z",
     "shell.execute_reply.started": "2023-11-22T09:16:59.461713Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'know intj tool use interaction people excuse antisocial truly enlighten mastermind know would count pet peeze something time matter people either whether group people mall never see best friend sit outside conversation jsut listen want interject sit formulate say wait inject argument thought find fascinate sit watch people talk people fascinate sit class watch different people find intrigue dad intj u stand look like line safeway watch people home talk people like think military job people voluntarily go job important show deference endanger live glorify way civilian think pretty ignorant general think military necessary defense mechanism political tactic feel like u specifically invest much money could put money education whatnot though personally sound budget aernative really comment one way base two politician eye year ago come name somewhat important kinda role model nowadays pick keep score individual level mean little vary accord number condition day may score high others low sweat really good cast physiotherapist like fiberglass cast break arm whatever sometimes want take picture beast put someone arm sadly people blind brilliance need tell directly wave arm frantically totally beyond oblivious get good eye contact help lot start find like attention get opposite sex notice however gay men tend little aggressive always walk away flatter like alcohol bad start generally keep go pas run money even mention fact crave cocaine drink political power mainly desire form power okay status still never study day life never learn study feel like real whatever reason college prepare recieve people like depend career introductory course help start rid bike write essay etc choose career least stimulate mind expand perspective reality without college like kiss sound ear yup roll end quite strange confession time mind wish people le judgemental self perceive flaw run situation person confess something expect judge one way another freak realize judge gasp human interpret acknowledgement sign terrible person agree bad impulse ditch safe place quickly become somewhere dump emotional trash gui free interest play role mind noise midnight still go make really cranky lol already know autistic even know asd associate intj people mind two even remotely similar card conspiracy hallmark post office long enough people whether individual people government conglomerate corporation understand biodiversity something need fund even though make money instead insurance policy fine aka negative external form cost need separate positive surplus cost much thing like seed bank visualize cost percent farm benefit cost yet need fund separately individual farmer individual farmer corporation think well someone else people free rider problem seed bank never get set stuff like government capitalism may provide innovation government set regulation prevent negative consequence unintentional externality seed bank get set half thousand differents solution perhaps general tax commerce usage fee similar california recycle fee electronics form donation pledge system regardless need get seed bank get expert truely know enough need biodiversity seed farm whether enough seed farm different location properly fund amp bsp say expert know enough due single college class involve economics say economic class involve lot history use case study green revolution'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['posts'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:59.472741Z",
     "iopub.status.busy": "2023-11-22T09:16:59.472393Z",
     "iopub.status.idle": "2023-11-22T09:16:59.481190Z",
     "shell.execute_reply": "2023-11-22T09:16:59.480383Z",
     "shell.execute_reply.started": "2023-11-22T09:16:59.472704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INTJ'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['type'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:59.482921Z",
     "iopub.status.busy": "2023-11-22T09:16:59.482553Z",
     "iopub.status.idle": "2023-11-22T09:16:59.503146Z",
     "shell.execute_reply": "2023-11-22T09:16:59.502396Z",
     "shell.execute_reply.started": "2023-11-22T09:16:59.482878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['INTJ', 'INTP', 'ISFJ', 'ISFP', 'ISTJ', 'ISTP', 'ENFJ', 'ENFP',\n",
       "       'ENTJ', 'ENTP', 'ESFJ', 'ESFP', 'ESTJ', 'ESTP', 'INFJ', 'INFP'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:59.504488Z",
     "iopub.status.busy": "2023-11-22T09:16:59.504247Z",
     "iopub.status.idle": "2023-11-22T09:16:59.512418Z",
     "shell.execute_reply": "2023-11-22T09:16:59.511392Z",
     "shell.execute_reply.started": "2023-11-22T09:16:59.504460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INTJ'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['type'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:59.513779Z",
     "iopub.status.busy": "2023-11-22T09:16:59.513543Z",
     "iopub.status.idle": "2023-11-22T09:16:59.533560Z",
     "shell.execute_reply": "2023-11-22T09:16:59.532733Z",
     "shell.execute_reply.started": "2023-11-22T09:16:59.513751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 16 types of classified MBTI posts\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total of {len(df['type'].unique())} types of classified MBTI posts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:59.535086Z",
     "iopub.status.busy": "2023-11-22T09:16:59.534826Z",
     "iopub.status.idle": "2023-11-22T09:16:59.574108Z",
     "shell.execute_reply": "2023-11-22T09:16:59.573307Z",
     "shell.execute_reply.started": "2023-11-22T09:16:59.535035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "posts    0\n",
       "type     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the number of posts per type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:59.575527Z",
     "iopub.status.busy": "2023-11-22T09:16:59.575271Z",
     "iopub.status.idle": "2023-11-22T09:16:59.717838Z",
     "shell.execute_reply": "2023-11-22T09:16:59.717062Z",
     "shell.execute_reply.started": "2023-11-22T09:16:59.575493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.6.3.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"75132231-a5a7-451b-a599-043a753ab23d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"75132231-a5a7-451b-a599-043a753ab23d\")) {                    Plotly.newPlot(                        \"75132231-a5a7-451b-a599-043a753ab23d\",                        [{\"x\":[\"ENFJ\",\"ENFP\",\"ENTJ\",\"ENTP\",\"ESFJ\",\"ESFP\",\"ESTJ\",\"ESTP\",\"INFJ\",\"INFP\",\"INTJ\",\"INTP\",\"ISFJ\",\"ISFP\",\"ISTJ\",\"ISTP\"],\"y\":[1534,6167,2955,11725,181,360,482,1986,14963,12134,22427,24961,650,875,1243,3424],\"type\":\"bar\"}],                        {\"title\":{\"text\":\"MBTI # Classified Posts per Type\"},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('75132231-a5a7-451b-a599-043a753ab23d');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_bar_chart=df.groupby('type').count()\n",
    "\n",
    "\n",
    "trace1 = go.Bar(x=df_bar_chart.index, y=df_bar_chart['posts'])\n",
    "\n",
    "data = [trace1]\n",
    "layout = go.Layout(title='MBTI # Classified Posts per Type')\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreate the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This machine learning model takes it's time to train data\n",
    "\n",
    "To avoid waiting every time, We're going to use the feature dump/load from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:59.719187Z",
     "iopub.status.busy": "2023-11-22T09:16:59.718962Z",
     "iopub.status.idle": "2023-11-22T09:16:59.722854Z",
     "shell.execute_reply": "2023-11-22T09:16:59.721996Z",
     "shell.execute_reply.started": "2023-11-22T09:16:59.719159Z"
    }
   },
   "outputs": [],
   "source": [
    "# Flag to re-create or not the machine learning model\n",
    "recreate_model=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:59.724311Z",
     "iopub.status.busy": "2023-11-22T09:16:59.724014Z",
     "iopub.status.idle": "2023-11-22T09:16:59.732620Z",
     "shell.execute_reply": "2023-11-22T09:16:59.731860Z",
     "shell.execute_reply.started": "2023-11-22T09:16:59.724271Z"
    }
   },
   "outputs": [],
   "source": [
    "# We'll save the model into a file:\n",
    "filename = 'mbti_svm_v2.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:59.734117Z",
     "iopub.status.busy": "2023-11-22T09:16:59.733636Z",
     "iopub.status.idle": "2023-11-22T09:16:59.742326Z",
     "shell.execute_reply": "2023-11-22T09:16:59.741552Z",
     "shell.execute_reply.started": "2023-11-22T09:16:59.734082Z"
    }
   },
   "outputs": [],
   "source": [
    "# If the model file doesn't exists\n",
    "if not os.path.isfile(filename):\n",
    "    recreate_model=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:59.747270Z",
     "iopub.status.busy": "2023-11-22T09:16:59.747025Z",
     "iopub.status.idle": "2023-11-22T09:16:59.773689Z",
     "shell.execute_reply": "2023-11-22T09:16:59.773131Z",
     "shell.execute_reply.started": "2023-11-22T09:16:59.747228Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df['posts'] # features\n",
    "y = df['type']  # labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:16:59.775124Z",
     "iopub.status.busy": "2023-11-22T09:16:59.774827Z",
     "iopub.status.idle": "2023-11-22T09:17:03.563812Z",
     "shell.execute_reply": "2023-11-22T09:17:03.562981Z",
     "shell.execute_reply.started": "2023-11-22T09:16:59.775089Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41f99a38a5448e08b72f2b774a37374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66873a62d7a4ebbb723f0087c2a85a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3c89f1d5074d1b9694e3c380e336e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77cd9d79dcc407e9b2fcf5351baac8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "# Assuming you have 'transformers' library installed, if not, you can install it using: pip install transformers\n",
    "\n",
    "# Combine both training and testing labels for encoding\n",
    "all_labels = y_train.append(y_test)\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform on the combined set of labels\n",
    "all_labels_encoded = label_encoder.fit_transform(all_labels)\n",
    "\n",
    "# Split the encoded labels back into training and testing sets\n",
    "y_train_encoded = all_labels_encoded[:len(y_train)]\n",
    "y_test_encoded = all_labels_encoded[len(y_train):]\n",
    "\n",
    "# Tokenizing the input text\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Tokenizing and encoding the training data\n",
    "train_encodings = tokenizer(list(X_train), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(list(X_test), truncation=True, padding=True)\n",
    "\n",
    "# Converting the data into PyTorch tensors\n",
    "train_dataset = TensorDataset(torch.tensor(train_encodings['input_ids']),\n",
    "                              torch.tensor(train_encodings['attention_mask']),\n",
    "                              torch.tensor(y_train_encoded))  # use the encoded labels\n",
    "\n",
    "test_dataset = TensorDataset(torch.tensor(test_encodings['input_ids']),\n",
    "                             torch.tensor(test_encodings['attention_mask']),\n",
    "                             torch.tensor(y_test_encoded))  # use the encoded labels\n",
    "\n",
    "# ... (rest of the code remains the same)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T14:48:02.013811Z",
     "iopub.status.busy": "2023-11-22T14:48:02.013283Z",
     "iopub.status.idle": "2023-11-22T14:48:02.020266Z",
     "shell.execute_reply": "2023-11-22T14:48:02.019569Z",
     "shell.execute_reply.started": "2023-11-22T14:48:02.013779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.joblib']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# Save the label encoder to a file\n",
    "joblib.dump(label_encoder, 'label_encoder.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:17:03.565785Z",
     "iopub.status.busy": "2023-11-22T09:17:03.565120Z",
     "iopub.status.idle": "2023-11-22T09:17:08.715015Z",
     "shell.execute_reply": "2023-11-22T09:17:08.714293Z",
     "shell.execute_reply.started": "2023-11-22T09:17:03.565744Z"
    }
   },
   "outputs": [],
   "source": [
    "Save the datasets\n",
    "torch.save(train_dataset, 'train_dataset.pth')\n",
    "torch.save(test_dataset, 'test_dataset.pth')\n",
    "\n",
    "# Load the datasets\n",
    "# train_dataset = torch.load('/kaggle/input/dataloader/train_dataset.pth')\n",
    "# test_dataset = torch.load('/kaggle/input/dataloader/test_dataset.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:17:08.716767Z",
     "iopub.status.busy": "2023-11-22T09:17:08.716395Z",
     "iopub.status.idle": "2023-11-22T09:17:08.780181Z",
     "shell.execute_reply": "2023-11-22T09:17:08.779565Z",
     "shell.execute_reply.started": "2023-11-22T09:17:08.716725Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "Save the tokenizer\n",
    "tokenizer.save_pretrained('tokenizer')\n",
    "\n",
    "# Now you can use loaded_tokenizer in your code\n",
    "# tokenizer = BertTokenizer.from_pretrained('/kaggle/input/tokenizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:17:08.781540Z",
     "iopub.status.busy": "2023-11-22T09:17:08.781311Z",
     "iopub.status.idle": "2023-11-22T09:17:30.691758Z",
     "shell.execute_reply": "2023-11-22T09:17:30.690940Z",
     "shell.execute_reply.started": "2023-11-22T09:17:08.781513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c3d55e539e4c13abb01425a4c81229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Defining the BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=7)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:17:30.693249Z",
     "iopub.status.busy": "2023-11-22T09:17:30.692980Z",
     "iopub.status.idle": "2023-11-22T09:17:30.696981Z",
     "shell.execute_reply": "2023-11-22T09:17:30.696209Z",
     "shell.execute_reply.started": "2023-11-22T09:17:30.693215Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# torch.cuda.empty()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Defining the BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(df['type'].unique()))\n",
    "\n",
    "# Defining the DataLoader for training and testing\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Defining the optimizer and loss function\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T09:21:47.568942Z",
     "iopub.status.busy": "2023-11-22T09:21:47.568688Z",
     "iopub.status.idle": "2023-11-22T14:12:08.802139Z",
     "shell.execute_reply": "2023-11-22T14:12:08.801148Z",
     "shell.execute_reply.started": "2023-11-22T09:21:47.568916Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 10607/10607 [58:18<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 1.0514, Accuracy: 68.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 10607/10607 [58:05<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Loss: 0.7746, Accuracy: 76.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 10607/10607 [58:00<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average Loss: 0.6868, Accuracy: 78.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 10607/10607 [58:00<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Average Loss: 0.6253, Accuracy: 80.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 10607/10607 [57:56<00:00,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Average Loss: 0.5743, Accuracy: 82.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from transformers import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=1, verbose=True)\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Training loop\n",
    "epochs = 5\n",
    "accumulation_steps = 4  # Adjust as needed\n",
    "batch_idx = 0  # Initialize batch index\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}'):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        inputs = {'input_ids': batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels': batch[2]}\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs.loss\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (batch_idx + 1) % accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        logits = outputs.logits\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        correct_predictions += (predicted == inputs['labels']).sum().item()\n",
    "        total_samples += inputs['labels'].size(0)\n",
    "\n",
    "        batch_idx += 1  # Increment batch index\n",
    "\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    accuracy = correct_predictions / total_samples * 100\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Average Loss: {average_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    scheduler.step(average_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T14:13:15.189323Z",
     "iopub.status.busy": "2023-11-22T14:13:15.188691Z",
     "iopub.status.idle": "2023-11-22T14:13:15.812534Z",
     "shell.execute_reply": "2023-11-22T14:13:15.811892Z",
     "shell.execute_reply.started": "2023-11-22T14:13:15.189289Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'mbti-model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T14:15:03.367855Z",
     "iopub.status.busy": "2023-11-22T14:15:03.367053Z",
     "iopub.status.idle": "2023-11-22T14:15:03.981824Z",
     "shell.execute_reply": "2023-11-22T14:15:03.980973Z",
     "shell.execute_reply.started": "2023-11-22T14:15:03.367815Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'mbti-model-complete.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluating the model\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T14:16:22.898376Z",
     "iopub.status.busy": "2023-11-22T14:16:22.897677Z",
     "iopub.status.idle": "2023-11-22T14:28:22.857370Z",
     "shell.execute_reply": "2023-11-22T14:28:22.856670Z",
     "shell.execute_reply.started": "2023-11-22T14:16:22.898340Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 2652/2652 [11:59<00:00,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 81.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc='Evaluating'):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        inputs = {'input_ids': batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels': batch[2]}\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        _, predicted = torch.max(logits, 1)\n",
    "        total += inputs['labels'].size(0)\n",
    "        correct += (predicted == inputs['labels']).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T14:32:32.249144Z",
     "iopub.status.busy": "2023-11-22T14:32:32.248396Z",
     "iopub.status.idle": "2023-11-22T14:32:32.777058Z",
     "shell.execute_reply": "2023-11-22T14:32:32.776308Z",
     "shell.execute_reply.started": "2023-11-22T14:32:32.249099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Replace these with your actual accuracy and loss values\n",
    "epoch_numbers = [1, 2, 3, 4, 5]\n",
    "train_accuracies = [68.26, 76.31, 78.93, 80.92, 82.44]\n",
    "train_losses = [1.0514, 0.7746, 0.6868, 0.6253, 0.5743]\n",
    "\n",
    "# Use a dark theme\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epoch_numbers, train_accuracies, marker='o', linestyle='-', color='b', label='Training Accuracy')\n",
    "plt.title('Training Accuracy Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epoch_numbers, train_losses, marker='o', linestyle='-', color='r', label='Training Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T14:16:02.772487Z",
     "iopub.status.busy": "2023-11-22T14:16:02.772210Z",
     "iopub.status.idle": "2023-11-22T14:16:02.778518Z",
     "shell.execute_reply": "2023-11-22T14:16:02.777796Z",
     "shell.execute_reply.started": "2023-11-22T14:16:02.772458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('INTJ',\n",
       " 'preferably p hd low except wew lad video p mind good reason agree statement relationship become difficu maintain people involve different stag life constantly feel though feign certain emotion counteract natural appearance aloofness excite someone engagement welcome someone bring child office internally really care either thing order mesh generally e office one strategically fake make act like thing matter family use phase anymore naturally open almost difficu fake around one occasion year feel obligate feign emotion actually comfortable around people overcome social anxiety fake emotion appear le detach completely different former take time persistent effort latter patch gauze cover wind former live fake learn comfort zone socially embrace people accept effort easily sniff counterfeit sense would take plenty vitamin get sunlight eat good visit r watchpeopledie appreciate life remember achieve thus far say intj resu trauma student study nurse something find interest body language fractal something think would really cool really understand yet mentalism one fact cool mundane common knowledge matter tell u something navajo apache descend single tribe migrate canada well sorta chief blame leaker source little foolish take basic precaution sort thing park car leave door unlock key ignition fau get steal thief still one primarily responsible idiot make easy say take photo compromise situation first place little like say could avoid theft never buy car technically true far inferior buy car lock door bed similar problem job hop since graduate land company nice crappy person like cuz still company first sale fairly well prep like excel amp nots lack severely customer service hat call finally somehow lose interest job scope initial good work erode allow shift logistics due exceptional initial stage thing happen fairly good lose focus job give another chance sale ask back logistics position feel crappy sale back logistics decide shift quality fairly well lose focus plus early stage pregnancy thus move back logistics light work tardy extend come work hour two late become moody temperamental pretty much keep barely make connection colleague surprise general manager amp ceo still ok come back maternity leave find none department want back cannot kick due local law woman back work maternity leave give final chance gm hr department new position company previously hire etc hr manager dual function finance amp hr function hr manager also temporary position finance position good get plan amp whatnot regard hire process etc course follow current cuure thats gm saw potiential sure say something genius people always one bad attitude agm speak highly person unsure real despite know lick type people work bring child goal well good environment go school etc happy planning carry thing etc punctuality wise amp interpersonally bad use lose motivation clear direction hr manager due position really hr finance really much teach even though know alot amp alot thing really find pro active point perhaps find work newly set company suggest way set direction amp planning heck even open get relevant people relevant thing master planner amp set direction best suggest vodka good stuff strong flavor smooth easy mix type')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['type'][2], df['posts'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T14:41:58.979621Z",
     "iopub.status.busy": "2023-11-22T14:41:58.979409Z",
     "iopub.status.idle": "2023-11-22T14:41:58.986978Z",
     "shell.execute_reply": "2023-11-22T14:41:58.986328Z",
     "shell.execute_reply.started": "2023-11-22T14:41:58.979595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('INTJ',\n",
       " 'u theagame say big problem people cannot comprehend see point problem arise thankfully really good mentor allow make mistake full production cycle show area improve say also show efficient way process volume data deal example change underlie query significantly improve speed one many process use take hour take minute honestly anything leverage intjs system style think ability see interconnection say system good thing cannot control well people work exactly like sculptor michelangelo begrudgingly take job family paint church ceiling machiavelli resume portfolio snide tongue cheek page turner amuse mass give birth political science ummm really plan think would address please hug touch stop use word already use word word help far use useless enfp go doubt sincerity word shut authenticity one key aspect intjs enfps authenticity fi style feel fe style human use jungian function enfps use fi nd spot thus primal aspect intjs fi user rd spot thus primal hide primal aspect call poker face le aware fi even though fi tie everything te effectiveness sometimes hide fi behind wall shield still hard see aka te make intjs feel stoic ni fi make intjs feel emotional aka link intjs amp bsp already know word fail either fail doubt work ask give answer ask permission hold enfp hand small table like restaurant establish eye contact eye contact establish make eye lock say want attention need say something important hard put word aka hand contact show enfp important go establish eye contact enfp go able literally since sincerity via eye lock use word keep short keep simple keep point word equal bad already use word enfp remember trust enfp remember reason word give enfp sensory feedback previous work poker face rob enfps word word word memory device trigger memory enfp trigger si connect present se hand hold eye lock allow enfp connect realize si se connect strong function hero function form pattern recognition enfps best call ne conceptualize pattern draw line data point data point b data point c give sincere heart fe apology enfp realize sincerity via hand hold eye lock job intj know hard intj shut fuck vulnerable let enfp control conversation likely enfp want move two page time fun enjoy small moment life word stop overthinking instead let watch second clip incredibles click youtube link edna e mode intj wonderful teach tool intjs channel often lead victory take charge intj fix problem assume responsibility also know control thing control watch clip hit elastigirl like edna instead hold hand see thing edna sincere little dramatic dramatic help understand intense emotion drive sincerity edna make lot eye contact go sign word edna sign clip ou show remember mr incredible remind well know go confront problem fight win edna return intense voice normal voice call get back darling enjoy visit ever get hat relationship eye yea see gonna next yeah thank give actual worldly advice tho lol well perceiver obvious especially know real difference si v ni type use te communicate motivation internal struggle even person mainly think focus pretty different')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['type'][4000], df['posts'][4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T14:39:47.811867Z",
     "iopub.status.busy": "2023-11-22T14:39:47.811106Z",
     "iopub.status.idle": "2023-11-22T14:39:47.817788Z",
     "shell.execute_reply": "2023-11-22T14:39:47.816983Z",
     "shell.execute_reply.started": "2023-11-22T14:39:47.811829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ISTJ',\n",
       " 'work lol thank ok istj however love swing f erratically however intrapersonal intelligence test show also describe n allmost tick everything however lot go head also however like explore f side thus give ability cry want need need release nearly cry private yes agree could make comment yet cant personal divulge intrested true friend post email find enfj forgive however happen would much hatred yes agree opersites facinating chance feel person hold istj build ideal moral grow personality hehehe know patience stick someone try force thing change realy pee mind im one beleive need someone little real life maybe past month get hour socialise op comment agree enough feel waste day life go im go say owiee head hurt agree istj enfp good istj keep much hide bottle sure let thing need good proportion time tell people thing skim around edge first cant afford second want linux mac window vista guess speak many istj problem change nsure leave alone like grey bug live load time seriously find people upgrade worry feel old im know good portion think however good become aware look someone go hurt phisically mental anguish pas time go bite flirt see operate track recorder damn reel huge lol thank god hard disk however im still get reel reel single track portable player dad correct comment full story im private person post skim around edge little however thing share doen hold much ditch aunt long ago confidant special time one state live near uk lass u good friend time sound like poor guy want get know good shut time may pick hint like say previous post really grey area hard might catch catch situation think least effect og job side note might like b ok something bore like walk route something everyday make think thing end day dream people sometimes alone bad someone thing yet beat normally people scar alone like date process try trust space dust light energy radiation fill even glass give energy even vacume space energy even dark matter sound like ok e hmm e public show know show select people trust n hmm n give hypertension super anxious time tense take propranolol bad panic attack hard leave house want understand brain work psychiatrist would put propranolol send new york washinon height hate neighborhood predominately spanish people always play music mad loud fit neighborhood anyone else feel lol awesome iguana know learn go dbt group see therapist psychiatrist schizotypal come like talk people keep job wanna normal party get pretty girl friend quit yesterday mid shift panic attack get whelm get super quite want get outta send iphone use tapatalk greg plitt hero someone inspire push get comfort zone philosophy mind set strong inspire send iphone use tapatalk start new job fit know talk people cool odd wash dish know look stand bull shi know people autism work hold job hand nervous fuck keep job change name iconclast admins contact well read autism relate social anxiety therapist go group everyday dbt make try overcome always')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['type'][50000], df['posts'][50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T14:39:38.324769Z",
     "iopub.status.busy": "2023-11-22T14:39:38.324086Z",
     "iopub.status.idle": "2023-11-22T14:39:38.330496Z",
     "shell.execute_reply": "2023-11-22T14:39:38.329745Z",
     "shell.execute_reply.started": "2023-11-22T14:39:38.324730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('INTP',\n",
       " 'need exactly le likely know mean mean intp extremely difficu time force maintenance type task clean apartment exercise thing nature find help little bite tackle small bit example half dish go something else little bite come back finish know help think necessarily put danger thing specifically fearful maybe need take experience extreme depend im really like picasso van gogh thing like like film character concept art landscape art fictional city like sometimes write use write lot fiction kid like see people creativity especially way literally see need much knowledge understand something creative sense im car person bc get part work really problem fi value make logical sense system ti even relation least discern ti tert well course say ti inherent mean value anything beside mechanical theoretical function curiosity work mean system reference logical within relation accurate le unless new information present everything reassess reposition correlate new data corrective function wise struggle inherent really depend individual live environment raise live problem emotion within first relationship come reject philosophy render existence essentially meaningless rationale especially relativism reject identity relative sure convenient ni free fe scream nothing mean relative constant also associate subjectivism like opinion man since use usually want dismiss others argument without explain shit fine agree disagree differ opinion fine long accept understand fma rotherhood good one think baccano awesome would vastly expand due obsolete need keep house close work environment open many new sector rural aesthetically please rural area assume teleportation free available like apparation harry potter universe conversely teleportation monetize go process expensive technology vr go would get typical company first exploit high disposable income create small niche market house market would correspondingly adapt create niche market mansion scatter around globe scenic probably tourist spot would buy mansion would also probably value place market tourist industry eventually market would expand include upper middle class technology evolve get cheap understand five language love would helpful lot sf nt relationship since generally follow certain dynamic approach affection lot room error misconception generally flexible try gregarious friend refuse move change someone try force anything usually take sort thing personal offense treat everything argument convince otherwise think right sound like intp get comfortable whatever guy sfs tendency challenge lot intp stand see struggle advice suggest walk away best friend conflict would blasphemy social dynamic incredibly unheahy use thesaurus far dictionary oh agree one debate truth post stink ignorance perhaps research slight lean amp amp least nice certain amount set aside student purchase super cheap one big grip college always eat cafeteria fresh produce cheap everyone would able cook every awhile yeah opinion fully form matter sound great could pull unfortunately like say freedom could issue straight male would tell intps general like person direct could well talk good side look prejudice analysis think shutter island really grow love day saw start clear basement e rarely take offense take offense irrationality truth though honest blunt direct something downright respect many people say many people intp even start doubt month test differents place come thing come')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['type'][30000], df['posts'][30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-22T14:40:51.668646Z",
     "iopub.status.busy": "2023-11-22T14:40:51.667965Z",
     "iopub.status.idle": "2023-11-22T14:41:58.978112Z",
     "shell.execute_reply": "2023-11-22T14:41:58.977513Z",
     "shell.execute_reply.started": "2023-11-22T14:40:51.668614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***********************************************\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a post (type 'exit' to quit):  need exactly le likely know mean mean intp extremely difficu time force maintenance type task clean apartment exercise thing nature find help little bite tackle small bit example half dish go something else little bite come back finish know help think necessarily put danger thing specifically fearful maybe need take experience extreme depend im really like picasso van gogh thing like like film character concept art landscape art fictional city like sometimes write use write lot fiction kid like see people creativity especially way literally see need much knowledge understand something creative sense im car person bc get part work really problem fi value make logical sense system ti even relation least discern ti tert well course say ti inherent mean value anything beside mechanical theoretical function curiosity work mean system reference logical within relation accurate le unless new information present everything reassess reposition correlate new data corrective function wise struggle inherent really depend individual live environment raise live problem emotion within first relationship come reject philosophy render existence essentially meaningless rationale especially relativism reject identity relative sure convenient ni free fe scream nothing mean relative constant also associate subjectivism like opinion man since use usually want dismiss others argument without explain shit fine agree disagree differ opinion fine long accept understand fma rotherhood good one think baccano awesome would vastly expand due obsolete need keep house close work environment open many new sector rural aesthetically please rural area assume teleportation free available like apparation harry potter universe conversely teleportation monetize go process expensive technology vr go would get typical company first exploit high disposable income create small niche market house market would correspondingly adapt create niche market mansion scatter around globe scenic probably tourist spot would buy mansion would also probably value place market tourist industry eventually market would expand include upper middle class technology evolve get cheap understand five language love would helpful lot sf nt relationship since generally follow certain dynamic approach affection lot room error misconception generally flexible try gregarious friend refuse move change someone try force anything usually take sort thing personal offense treat everything argument convince otherwise think right sound like intp get comfortable whatever guy sfs tendency challenge lot intp stand see struggle advice suggest walk away best friend conflict would blasphemy social dynamic incredibly unheahy use thesaurus far dictionary oh agree one debate truth post stink ignorance perhaps research slight lean amp amp least nice certain amount set aside student purchase super cheap one big grip college always eat cafeteria fresh produce cheap everyone would able cook every awhile yeah opinion fully form matter sound great could pull unfortunately like say freedom could issue straight male would tell intps general like person direct could well talk good side look prejudice analysis think shutter island really grow love day saw start clear basement e rarely take offense take offense irrationality truth though honest blunt direct something downright respect many people say many people intp even start doubt month test differents place come thing come\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Personality Type: INTP\n",
      "\n",
      "***********************************************\n",
      "\n",
      "\n",
      "***********************************************\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a post (type 'exit' to quit):  work lol thank ok istj however love swing f erratically however intrapersonal intelligence test show also describe n allmost tick everything however lot go head also however like explore f side thus give ability cry want need need release nearly cry private yes agree could make comment yet cant personal divulge intrested true friend post email find enfj forgive however happen would much hatred yes agree opersites facinating chance feel person hold istj build ideal moral grow personality hehehe know patience stick someone try force thing change realy pee mind im one beleive need someone little real life maybe past month get hour socialise op comment agree enough feel waste day life go im go say owiee head hurt agree istj enfp good istj keep much hide bottle sure let thing need good proportion time tell people thing skim around edge first cant afford second want linux mac window vista guess speak many istj problem change nsure leave alone like grey bug live load time seriously find people upgrade worry feel old im know good portion think however good become aware look someone go hurt phisically mental anguish pas time go bite flirt see operate track recorder damn reel huge lol thank god hard disk however im still get reel reel single track portable player dad correct comment full story im private person post skim around edge little however thing share doen hold much ditch aunt long ago confidant special time one state live near uk lass u good friend time sound like poor guy want get know good shut time may pick hint like say previous post really grey area hard might catch catch situation think least effect og job side note might like b ok something bore like walk route something everyday make think thing end day dream people sometimes alone bad someone thing yet beat normally people scar alone like date process try trust space dust light energy radiation fill even glass give energy even vacume space energy even dark matter sound like ok e hmm e public show know show select people trust n hmm n give hypertension super anxious time tense take propranolol bad panic attack hard leave house want understand brain work psychiatrist would put propranolol send new york washinon height hate neighborhood predominately spanish people always play music mad loud fit neighborhood anyone else feel lol awesome iguana know learn go dbt group see therapist psychiatrist schizotypal come like talk people keep job wanna normal party get pretty girl friend quit yesterday mid shift panic attack get whelm get super quite want get outta send iphone use tapatalk greg plitt hero someone inspire push get comfort zone philosophy mind set strong inspire send iphone use tapatalk start new job fit know talk people cool odd wash dish know look stand bull shi know people autism work hold job hand nervous fuck keep job change name iconclast admins contact well read autism relate social anxiety therapist go group everyday dbt make try overcome always\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Personality Type: ISTJ\n",
      "\n",
      "***********************************************\n",
      "\n",
      "\n",
      "***********************************************\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a post (type 'exit' to quit):  drink like wish could drink red wine give headache almost instantaneously apparently people really sensitive byproduct red wine esfp bite place blissful go flow state change anything brother middle right thread really help realize need change honestly assume op know try make funny post even giggle also wonder would downvote guy people get mad get joke really know suppose one minority social recluse would quite sad buddhist strong humanist lean particularly see much geographical difference two hate sleep waste time hard stop think enough brain turn jesus christ close home every weeknight conversation wife believe men attract status way believe get degree somehow ensure end guy least much education status thing false agree false disagree woman know good woman want men high status feel like unfair smv increase status standard keep get high value stay woman good grip reality social interaction smv like reality like complain motivation go college first place largely conformism parent say society say friend go seem like fun experience go along woman naturally tend go soft subject lot social component like social science often work people help people way also value flexibility cooperation personal time competition success make sense biologically one birth raise child need aggression need social skill time child really conspiracy plot lock man biology conform society look high status male choose career field social nurture side allow raise child except iq kill unstoppable oh well guess settle mid fine long one see browser history ne seem like river manifold muiple weak current whereas ni seem like river strong current look right hate brainstorm like idea want solve problem get little bubble let brain come mental representation manipulate thing solve even try answer visualize powerfull stream water dig canyon image partially suggest mental image get strong feel like take shower edit clarity thank chan basically semi meta circlejerk implode muiple time meme cuure become obscure point exist make sense within chan like reddit everyone compete internet point everyone chan equally unimportant credit go nobody shit create simply create sake exist chan use shitty rise community chan remain odd one like wild west community cuure allow mature fester today vastly fascinate back chan use nothing literally flavor chip tune remixes still sound like chip tune sure hear thing outside professional work game example castlevania series song vampire killer first level first ne game redo dozen time castlevania iii case chip different arrangement hear backward remixes music game bite late generation devolve chip tune usually like come preferable original music old chip authentic chip tune something could original chip hardware accept tune bui use ne sample authentically example norrin radd anomaly least authentic day famitracker good enough produce ne music actually play ne authentic example jake kaufman fx originally fake sound like ne track remastered famitracker mega man example professional work sound like ne still cheat little plot thicken get feel perhaps something else go would mind go assumption like sound like analyze potential make incorrect statement head sound like defense mechanism straight really intj thing kerbal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Personality Type: INTP\n",
      "\n",
      "***********************************************\n",
      "\n",
      "\n",
      "***********************************************\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a post (type 'exit' to quit):  preferably p hd low except wew lad video p mind good reason agree statement relationship become difficu maintain people involve different stag life constantly feel though feign certain emotion counteract natural appearance aloofness excite someone engagement welcome someone bring child office internally really care either thing order mesh generally e office one strategically fake make act like thing matter family use phase anymore naturally open almost difficu fake around one occasion year feel obligate feign emotion actually comfortable around people overcome social anxiety fake emotion appear le detach completely different former take time persistent effort latter patch gauze cover wind former live fake learn comfort zone socially embrace people accept effort easily sniff counterfeit sense would take plenty vitamin get sunlight eat good visit r watchpeopledie appreciate life remember achieve thus far say intj resu trauma student study nurse something find interest body language fractal something think would really cool really understand yet mentalism one fact cool mundane common knowledge matter tell u something navajo apache descend single tribe migrate canada well sorta chief blame leaker source little foolish take basic precaution sort thing park car leave door unlock key ignition fau get steal thief still one primarily responsible idiot make easy say take photo compromise situation first place little like say could avoid theft never buy car technically true far inferior buy car lock door bed similar problem job hop since graduate land company nice crappy person like cuz still company first sale fairly well prep like excel amp nots lack severely customer service hat call finally somehow lose interest job scope initial good work erode allow shift logistics due exceptional initial stage thing happen fairly good lose focus job give another chance sale ask back logistics position feel crappy sale back logistics decide shift quality fairly well lose focus plus early stage pregnancy thus move back logistics light work tardy extend come work hour two late become moody temperamental pretty much keep barely make connection colleague surprise general manager amp ceo still ok come back maternity leave find none department want back cannot kick due local law woman back work maternity leave give final chance gm hr department new position company previously hire etc hr manager dual function finance amp hr function hr manager also temporary position finance position good get plan amp whatnot regard hire process etc course follow current cuure thats gm saw potiential sure say something genius people always one bad attitude agm speak highly person unsure real despite know lick type people work bring child goal well good environment go school etc happy planning carry thing etc punctuality wise amp interpersonally bad use lose motivation clear direction hr manager due position really hr finance really much teach even though know alot amp alot thing really find pro active point perhaps find work newly set company suggest way set direction amp planning heck even open get relevant people relevant thing master planner amp set direction best suggest vodka good stuff strong flavor smooth easy mix type\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Personality Type: INTJ\n",
      "\n",
      "***********************************************\n",
      "\n",
      "\n",
      "***********************************************\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a post (type 'exit' to quit):  exit\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Load tokenizer from directory\n",
    "tokenizer = BertTokenizer.from_pretrained('/kaggle/input/tokenizer')\n",
    "\n",
    "# Load the saved complete model\n",
    "model = torch.load('/kaggle/working/mbti-model-complete.pth')\n",
    "\n",
    "# Set the device (either 'cuda' for GPU or 'cpu' for CPU)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Move the model to the same device as the input data\n",
    "model.to(device)\n",
    "\n",
    "def predict_class(input_text):\n",
    "    # Tokenize and encode the input text\n",
    "    input_ids = tokenizer.encode(input_text, add_special_tokens=True, max_length=512, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Move the input data to the same device as the model\n",
    "    input_ids = input_ids.to(device)\n",
    "\n",
    "    # Make the prediction\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        logits = model(input_ids)[0]\n",
    "\n",
    "    # Get the predicted class\n",
    "    predicted_class = torch.argmax(logits).item()\n",
    "\n",
    "    return predicted_class\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Take user input\n",
    "    print(f\"\\n***********************************************\\n\")\n",
    "   \n",
    "    user_input = input(\"Enter a post (type 'exit' to quit): \")\n",
    "\n",
    "    # Check if the user wants to exit\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    # Tokenize and encode the input text\n",
    "    input_ids = tokenizer.encode(user_input, add_special_tokens=True, max_length=512, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Move the input data to the same device as the model\n",
    "    input_ids = input_ids.to(device)\n",
    "\n",
    "    # Make the prediction\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        logits = model(input_ids)[0]\n",
    "\n",
    "    # Get the predicted class\n",
    "    predicted_class = torch.argmax(logits).item()\n",
    "\n",
    "    # Decode the predicted class using the label encoder\n",
    "    predicted_label = label_encoder.inverse_transform([predicted_class])[0]\n",
    "\n",
    "    print(f\"\\nPredicted Personality Type: {predicted_label}\")\n",
    "    print(f\"\\n***********************************************\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1831626,
     "sourceId": 2988740,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4040107,
     "sourceId": 7025185,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4040117,
     "sourceId": 7025200,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
